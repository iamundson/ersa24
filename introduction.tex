% PROVERS
Formal methods provides a mathematically rigorous means of verification that one would expect for the development of high-assurance systems such as those in the aerospace and defense industries. Certification guidance has even been published on how formal methods can be used to satisfy airworthiness objectives for airborne software in commercial aircraft~\cite{DO-333}.  However, despite the effectiveness of these powerful proof techniques, their adoption into traditional development processes has been slow and uneven.  Reasons for slow uptake include scalability limitations of the underlying algorithms, poorly designed user interfaces and other tool usability factors, and the need for formal training and often an advanced degree just to properly use them~\cite{?}.

The DARPA Pipelined Reasoning of Verifiers Enabling Robust Systems (PROVERS) program was recently launched with the goal of producing scalable and usable formal methods tools that can be integrated into traditional aerospace and defense development processes.  Specifically, a key outcome of the program is that product engineers with minimal formal methods background will be able to benefit from these powerful technologies, further driving their adoption while simultaneously improving product dependability.

% INSPECTA
To address these challenges, our team is developing the Industrial-Scale Proof-Engineering for Critical Trustworthy Applications (INSPECTA) framework.  INSPECTA consists of \textit{ProofOps} and \textit{BuildOps} tools and methods that integrate with current aerospace DevOps pipelines and achieve provably correct design and implementation at each level of the system hierarchy.  In order to address the key objectives of PROVERS, we pay particular attention to addressing scalability and explainability concerns with respect to the proof tools in our framework.

% Compositional Reasoning
Within the ProofOps workflow, INSPECTA uses the Assume-Guarantee Reasoning Environment (AGREE)~\cite{compositional-analysis-agree}, a formal compositional reasoning tool for Architecture Analysis and Design Language (AADL)~\cite{feiler-aadl} models.
Compositional reasoning partitions the formal analysis of a complex system architecture into verification tasks corresponding to the architecture's decomposition.  By partitioning the verification effort into proofs about each subsystem within the architecture, the analysis will scale to handle large system designs.

Although AGREE does not suffer from some of the scalability issues inherent in other formal methods frameworks due to the compositional nature of the analysis, generated counterexamples can still be difficult to understand, especially for formal methods novices when the counterexamples contain several steps, each consisting of multiple variables.  This problem is not unique to AGREE, but is common to most model checkers in use today~\cite{?}.  
Recently, however, a novel approach to producing explainable counterexamples has emerged in the form of generative AI.

%AMER - CAN YOU ADD A PARAGRAPH HERE WITH REFERENCES ON OTHER RESEARCH THAT USES GENERATIVE AI FOR PROOF ASSISTANCE?

%AT: I added a related work section, see section 3. % Generative AI has been applied to proof assistance in theorem proving~\cite{} ... 

In this paper, we present our current work on using generative AI to provide clear and concise explanations of counterexamples generated by AGREE.  Our initial results indicate this approach is well-suited to providing clear explanations of root cause, and even provide suggestions for addressing the contract violations.